#!/usr/bin/env python3
"""
sql_generator.py

Takes a JSON schema generated by `index.py` (sample_output.json) and produces
PostgreSQL DDL to create a corresponding table, including join tables for relations
and a metadata table with property schema details.

Usage:
  python sql_generator.py --input sample_output.json [--table-name my_table] [--output schema.sql]

If --table-name is omitted, defaults to `db_<database_id>`.
"""
import sys
import json
import argparse
import re

# Mapping of Notion types to PostgreSQL types
NOTION_TO_PG = {
    'title': 'TEXT',
    'rich_text': 'TEXT',
    'number': 'NUMERIC',
    'select': 'TEXT',
    'multi_select': 'TEXT[]',
    'date': 'TIMESTAMPTZ',
    'people': 'JSONB',
    'files': 'JSONB',
    'checkbox': 'BOOLEAN',
    'url': 'TEXT',
    'email': 'TEXT',
    'phone_number': 'TEXT',
    'formula': 'TEXT',
    'relation': 'UUID',  # single UUID; join table handles many-to-many
    'rollup': 'JSONB',
    'created_time': 'TIMESTAMPTZ',
    'last_edited_time': 'TIMESTAMPTZ',
    'status': 'TEXT',
    'created_by': 'TEXT',
    'last_edited_by': 'TEXT'
}

def slugify(name: str) -> str:
    """Convert a property name to a valid SQL identifier."""
    s = re.sub(r'[^0-9a-zA-Z_]', '_', name).lower()
    s = re.sub(r'_+', '_', s).strip('_')
    if re.match(r'^[0-9]', s):
        s = 'col_' + s
    return s or 'col'


def generate_ddl(schema: dict, table_name: str) -> str:
    """Generate CREATE TABLE DDL for all properties, treating relations as UUID arrays."""
    props = schema.get('properties', {})
    main_lines = ['  "id" UUID PRIMARY KEY']

    for prop_name, meta in props.items():
        ptype = meta.get('type')
        col_name = slugify(prop_name)

        if ptype == 'relation':
            # store related page IDs as an array; add join tables later if needed
            pg_type = 'UUID[]'
        elif ptype == 'rollup':
            func = meta.get('rollup_function', '').lower()
            if func in ('count', 'count_all'):
                pg_type = 'INTEGER'
            elif func in ('sum', 'average', 'min', 'max'):
                pg_type = 'NUMERIC'
            else:
                pg_type = 'JSONB'
        else:
            pg_type = NOTION_TO_PG.get(ptype, 'TEXT')

        main_lines.append(f'  "{col_name}" {pg_type}')

    # Build CREATE TABLE for main table only
    ddl = [
        f'CREATE TABLE "{table_name}" (',
        ',\n'.join(main_lines),
        ');'
    ]
    return '\n'.join(ddl)


def generate_schema_metadata(schema: dict, table_name: str) -> str:
    """Generate SQL for a metadata table capturing property schema details."""
    props = schema.get('properties', {})
    meta_table = f'{table_name}__schema'
    lines = [
        f'CREATE TABLE "{meta_table}" (',
        '  "property_id" TEXT PRIMARY KEY,',
        '  "property_name" TEXT NOT NULL,',
        '  "column_name" TEXT NOT NULL,',
        '  "type" TEXT NOT NULL,',
        '  "metadata" JSONB NOT NULL',
        ');'
    ]
    inserts = []
    for name, meta in props.items():
        col = slugify(name)
        ptype = meta.get('type', '')
        meta_json = json.dumps(meta).replace("'", "''")
        name_esc = name.replace("'", "''")
        inserts.append(
            f"('{name_esc}', '{col}', '{ptype}', '{meta_json}'::JSONB)"
        )
    if inserts:
        lines.append(f'INSERT INTO "{meta_table}" (property_name, column_name, type, metadata) VALUES')
        lines.append(',\n'.join(['  ' + v for v in inserts]) + ';')
    return '\n'.join(lines)


def main():
    parser = argparse.ArgumentParser(description='Generate PostgreSQL DDL from Notion JSON schema')
    parser.add_argument('--input', '-i', required=True, help='Path to JSON schema file')
    parser.add_argument('--table-name', '-t', help='Name of the SQL table to create')
    parser.add_argument('--output', '-o', default='database_schema.sql', help='Path to write SQL output')
    args = parser.parse_args()

    try:
        with open(args.input, 'r', encoding='utf-8') as f:
            schema = json.load(f)
    except Exception as e:
        print(f'Error reading JSON file: {e}', file=sys.stderr)
        sys.exit(1)

# Determine SQL table name: CLI override > database title slug > fallback to ID-based name
if args.table_name:
    tbl = args.table_name
else:
    db_title = schema.get('database_title', '').strip()
    if db_title:
        tbl = slugify(db_title)
    else:
        tbl = 'db_' + schema.get('database_id', 'unknown_db').replace('-', '_')

    # generate DDL and metadata
    ddl_main = generate_ddl(schema, tbl)
    ddl_meta = generate_schema_metadata(schema, tbl)
    full = ddl_main + "\n\n" + ddl_meta

    try:
        with open(args.output, 'w', encoding='utf-8') as f:
            f.write(full)
        print(f"SQL DDL + metadata written to {args.output}")
    except Exception as e:
        print(f'Error writing SQL file: {e}', file=sys.stderr)
        sys.exit(1)

if __name__ == '__main__':
    main()